{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Multiclass classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('X shape:', (5000, 400))\n",
      "('y shape:', (5000, 1))\n"
     ]
    }
   ],
   "source": [
    "matdata = sio.loadmat(\"ex3data1.mat\", struct_as_record = False)\n",
    "\n",
    "global y\n",
    "global X\n",
    "global y_one\n",
    "global lambda_\n",
    "\n",
    "X = matdata['X'] \n",
    "y = matdata['y']\n",
    "\n",
    "print(\"X shape:\",X.shape)\n",
    "print(\"y shape:\",y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Visualizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels:\n",
      "[[ 10.  10.  10.  10.  10.]\n",
      " [ 10.   1.   1.   2.   1.]\n",
      " [  2.   2.   3.  10.   1.]\n",
      " [  1.   2.   1.   4.   5.]\n",
      " [  4.   4.   2.   5.   4.]]\n"
     ]
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "y_labels = np.zeros((25))\n",
    "for i in range(1,26):\n",
    "    idx = i*np.random.randint(1,150) # Random image index\n",
    "    \n",
    "    # Show image\n",
    "    ax = fig.add_subplot(5,5,i)\n",
    "    ax.matshow(X[idx,:].reshape(20,20), interpolation='nearest', cmap=plt.cm.gray)\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    \n",
    "    y_labels[i-1] = (y[idx][0]) # Add label\n",
    "\n",
    "print(\"Labels:\")\n",
    "print(y_labels.reshape(5,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Vectorizing logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1, 1.3.2, 1.3.3 Vectorizing cost function and gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"Logistic regression func, returns probability\"\"\"\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "def lrCostFunction(theta,X_,y_,lambda_arg):\n",
    "    \"\"\"Unregularized cost function\"\"\"\n",
    "    J = 0\n",
    "    m = y_.size\n",
    "    grad = np.zeros((theta.size,1))\n",
    "    \n",
    "    # correct theta shape\n",
    "    theta.shape = (theta.shape[0],1)\n",
    "    \n",
    "    h = sigmoid(X.dot(theta))\n",
    "    h.shape = (h.size,1)\n",
    "    \n",
    "    J = (-1.0/m) * sum( y_.T.dot(np.log(h)) + (1-y_.T).dot(np.log(1-h)) )\n",
    "    # Regularize the cost function - except theta[0]\n",
    "    J += (lambda_arg/(2.0*m)) * sum(np.power(theta[1:],2))\n",
    "    \n",
    "    \n",
    "    grad = (1.0/m) * sum((h-y_).T.dot(X_))\n",
    "    grad.shape = (grad.shape[0],1) # correct shape\n",
    "    # Regularize grad, except grad[0]\n",
    "    grad[1:] += (lambda_arg/m) * theta[1:] \n",
    "    \n",
    "    # Fminunc expects single value\n",
    "    return J, grad.T.flatten()\n",
    "\n",
    "def decorated_lrCostFunction(theta):\n",
    "    \"\"\"Cost function wrapper for fminunc that returns only cost\"\"\"\n",
    "    J, grad = lrCostFunction(theta,X,y_one,lambda_)\n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1.4 One vs All classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Minimize using scipy fmin\n",
    "import scipy.optimize as opt\n",
    "\n",
    "\n",
    "def oneVsAll(num_labels, lambda_arg):\n",
    "    \"\"\"\"trains LR classifier and return classifier params in matrix\"\"\"\n",
    "    m = X.shape[0]\n",
    "    n = X.shape[1]\n",
    "    \n",
    "    # This has to be returned\n",
    "    all_theta = np.zeros((num_labels, n+1))\n",
    "    \n",
    "    # global var y_one\n",
    "    \n",
    "    lambda_ = lambda_arg\n",
    "    \n",
    "    \n",
    "    # Add ones to X\n",
    "    X = np.hstack((np.ones([m,1]), X))\n",
    "    \n",
    "    # Train classifier for each label\n",
    "    for i in range(num_labels):\n",
    "        y_one = (y == i)\n",
    "        all_theta[i,:] = opt.fmin(decorated_lrCostFunction, all_theta[i,:], maxiter=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'X' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-67564797e684>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moneVsAll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-38-76519efab57a>\u001b[0m in \u001b[0;36moneVsAll\u001b[0;34m(num_labels, lambda_arg)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0moneVsAll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_arg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;34m\"\"\"\"trains LR classifier and return classifier params in matrix\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'X' referenced before assignment"
     ]
    }
   ],
   "source": [
    "oneVsAll(9,0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
